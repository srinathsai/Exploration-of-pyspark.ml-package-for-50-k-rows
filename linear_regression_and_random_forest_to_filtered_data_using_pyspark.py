# -*- coding: utf-8 -*-
"""Linear regression and random forest to filtered data using pyspark.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y_iUjDUA7_O0bFa5CJNACSdsFMyDqKaO
"""

!pip install pyspark

from pyspark.sql import SparkSession  #Iimporting spark session.
spark = SparkSession.builder.appName("Task2").getOrCreate()
df = spark.read.csv('/content/original_data.csv',header =True, inferSchema=True)



from pyspark.sql import functions as F
cols = [f"any({col} is null) as {col}" for col in df.columns]
df.selectExpr(cols).show()
df.show()

df.dtypes

#using Linear regression.

from pyspark.ml.linalg import Vectors
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.feature import Imputer
from pyspark.sql.types import IntegerType
from pyspark.sql.functions import col
df1=df.select(df['researchExp'],df['industryExp'],df['cgpa'],df['admit'])
df1.dtypes

assembler =VectorAssembler(inputCols=['researchExp','industryExp','cgpa'],outputCol='features')

output=assembler.transform(df1)

final_df=output.select('features','admit')

train_data,test_data=final_df.randomSplit([0.8,0.2],seed=50)

train_data.describe().show()

test_data.describe().show()

from pyspark.ml.regression import LinearRegression
lm=LinearRegression(labelCol='admit')
model=lm.fit(train_data)

m=round(model.coefficients[0],2)
b=round(model.intercept,2)
print(f"""the formula for linear regression is admit={m}*features+{b}""")

import pandas as pd
pd.DataFrame({"Coefficients" : model.coefficients},index=['researchExp','industryExp','cgpa'])

res=model.evaluate(test_data)
res.residuals.show()

unlabelled_data=test_data.select('features')
predictions=model.transform(unlabelled_data)
print("MAE:" , res.meanAbsoluteError)
print("MSE:", res.meanSquaredError)
print("RMSE :",res.rootMeanSquaredError)
print("R2:",res.r2)
print("Adj R2:",res.r2adj)

# Using random forest

df2=df.select(df['researchExp'],df['industryExp'],df['cgpa'],df['admit'])
df2.dtypes

df2.groupBy("admit").count().show()

from pyspark.ml.feature import VectorAssembler
assembler=VectorAssembler(inputCols=['researchExp','industryExp','cgpa'],outputCol="features")

output2=assembler.transform(df2)

output2.select(["features","admit"]).show()

model_df=output2.select(["features","admit"])
training_df,testing_df=model_df.randomSplit([0.8,0.2],seed=50)

training_df.count()

testing_df.count()

from pyspark.ml.classification import RandomForestClassifier
rf_classifier=RandomForestClassifier(labelCol="admit",numTrees=50).fit(training_df)

rf_predictions=rf_classifier.transform(testing_df)
rf_predictions.show()

from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.evaluation import RegressionEvaluator
evaluator = RegressionEvaluator(labelCol="admit", metricName="rmse")
rmse = evaluator.evaluate(rf_predictions)
print(rmse)
rf_auc=BinaryClassificationEvaluator(labelCol="admit").evaluate(rf_predictions)
rf_auc
